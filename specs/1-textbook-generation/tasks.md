# Implementation Tasks: AI-Native Textbook with RAG Chatbot

**Feature**: `1-textbook-generation` | **Date**: 2025-12-06 | **Phase**: Tasks (Phase 2)  
**Status**: Ready for implementation | **Input**: specs/1-textbook-generation/plan.md

## Task Phases & Execution Flow

```
Phase 1: SETUP (sequential)
  â”œâ”€ T-001: Initialize project structure
  â”œâ”€ T-002: Setup dependencies (frontend)
  â””â”€ T-003: Setup dependencies (backend)

Phase 2: DATA & CONTRACTS (parallel [P])
  â”œâ”€ [P] T-010: Implement data models (Pydantic + SQLAlchemy)
  â”œâ”€ [P] T-011: Create database migrations (Alembic)
  â””â”€ [P] T-012: Document entity relationships

Phase 3: CORE COMPONENTS (parallel [P])
  â”œâ”€ [P] T-020: Build chatbot widget (React component)
  â”œâ”€ [P] T-021: Implement embedding service (MiniLM)
  â”œâ”€ [P] T-022: Implement retrieval service (Qdrant)
  â””â”€ [P] T-023: Build FastAPI app structure

Phase 4: API & INTEGRATION (sequential)
  â”œâ”€ T-030: Implement /api/v1/chat endpoint
  â”œâ”€ T-031: Implement /api/v1/health endpoint
  â”œâ”€ T-032: Connect Qdrant client
  â””â”€ T-033: Connect Neon PostgreSQL

Phase 5: TESTING (parallel [P])
  â”œâ”€ [P] T-040: Unit tests (embedding, retrieval)
  â”œâ”€ [P] T-041: Unit tests (chatbot orchestration)
  â”œâ”€ [P] T-042: Integration tests (RAG pipeline)
  â””â”€ [P] T-043: Contract tests (API schemas)

Phase 6: OBSERVABILITY & DEPLOYMENT (sequential)
  â”œâ”€ T-050: Implement structured logging
  â”œâ”€ T-051: Setup CI/CD pipeline (GitHub Actions)
  â”œâ”€ T-052: Configure deployment (GitHub Pages + Vercel)
  â””â”€ T-053: Performance & load testing

Phase 7: POLISH (parallel [P])
  â”œâ”€ [P] T-060: Documentation & API docs
  â”œâ”€ [P] T-061: Error handling & edge cases
  â””â”€ [P] T-062: Code quality (linting, type checking)

Phase 8: VALIDATION & LAUNCH (sequential)
  â”œâ”€ T-070: Full end-to-end testing
  â”œâ”€ T-071: Production deployment
  â””â”€ T-072: Monitor & collect feedback
```

---

## Detailed Task Breakdown

### Phase 1: SETUP

#### T-001: Initialize Project Structure âœ… READY

**Purpose**: Create directory structure, configuration files, and git setup

**Files to Create/Modify**:
```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ db/
â”‚   â””â”€â”€ scripts/
â”œâ”€â”€ tests/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ Dockerfile
â””â”€â”€ pyproject.toml

docs/
â”œâ”€â”€ chapter-1-intro-physical-ai/
â”‚   â”œâ”€â”€ _category_.json
â”‚   â””â”€â”€ index.md (stub)
â”œâ”€â”€ chapter-2-humanoid-robotics/
â”‚   â”œâ”€â”€ _category_.json
â”‚   â””â”€â”€ index.md (stub)
[... 4 more chapters ...]

.gitignore (verify/create)
.dockerignore (create)
```

**Acceptance Criteria**:
- [ ] Directory structure created
- [ ] .gitignore exists (includes `__pycache__/`, `*.pyc`, `.venv/`, `.env`, `node_modules/`, `build/`, `dist/`)
- [ ] .dockerignore created (includes `node_modules/`, `.git/`, `__pycache__/`, `.venv/`, `*.log`)
- [ ] All stub files created
- [ ] No errors on `git status`

**Files Modified**: 0 (new files only)

---

#### T-002: Setup Frontend Dependencies âœ… READY

**Purpose**: Initialize Docusaurus + React dependencies

**Command**:
```bash
cd book-website
yarn install
```

**Files to Create/Modify**:
- `book-website/package.json` (verify Docusaurus 3.x, React 18+)
- `book-website/node_modules/` (generated)
- `book-website/yarn.lock` (generated)

**Acceptance Criteria**:
- [ ] `yarn install` succeeds without errors
- [ ] Docusaurus version >= 3.0
- [ ] React version >= 18.0
- [ ] `yarn start` command available
- [ ] No peer dependency warnings

**Files Modified**: 1 (package.json verify)

---

#### T-003: Setup Backend Dependencies âœ… READY

**Purpose**: Create virtual environment + install Python packages

**Commands**:
```bash
cd backend
python3.11 -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install --upgrade pip setuptools wheel
pip install -r requirements.txt
```

**Files to Create/Modify**:
- `backend/requirements.txt` (create with dependencies)
- `backend/venv/` (generated)

**requirements.txt Contents**:
```
fastapi==0.104.1
uvicorn==0.24.0
pydantic==2.5.0
sqlalchemy==2.0.23
asyncpg==0.29.0
alembic==1.13.0
qdrant-client==2.7.0
sentence-transformers==2.2.2
python-multipart==0.0.6
python-dotenv==1.0.0
structlog==23.2.0
pytest==7.4.3
pytest-asyncio==0.21.1
httpx==0.25.2
```

**Acceptance Criteria**:
- [ ] Virtual environment created
- [ ] `pip install -r requirements.txt` succeeds
- [ ] `python -c "import fastapi; print(fastapi.__version__)"` works
- [ ] `python -c "import sentence_transformers; print('OK')"` works
- [ ] No unresolved dependencies

**Files Modified**: 1 (requirements.txt create)

---

### Phase 2: DATA & CONTRACTS

#### T-010: Implement Data Models (Pydantic + SQLAlchemy) [P]

**Purpose**: Define ORM models + API request/response schemas

**Files to Create/Modify**:
- `backend/src/models/__init__.py`
- `backend/src/models/chapter.py` â€” SQLAlchemy Chapter model
- `backend/src/models/section.py` â€” SQLAlchemy Section model
- `backend/src/models/chunk.py` â€” SQLAlchemy DocumentChunk model
- `backend/src/models/embedding.py` â€” SQLAlchemy Embedding model
- `backend/src/models/query.py` â€” Pydantic + SQLAlchemy models
- `backend/src/models/response.py` â€” Pydantic + SQLAlchemy models
- `backend/src/models/session.py` â€” UserSession model
- `backend/src/models/error_log.py` â€” ErrorLog model

**Acceptance Criteria**:
- [ ] All 8 entity models created with full field definitions
- [ ] SQLAlchemy models include `__tablename__`, relationships, constraints
- [ ] Pydantic models include validation rules + examples
- [ ] All models pass type checking (`mypy`)
- [ ] No duplicate field names across entities
- [ ] Relationships correctly defined (ForeignKeys, backrefs)

**Dependencies**: None (can run parallel)

**Estimated Time**: 3-4 hours

---

#### T-011: Create Database Migrations [P]

**Purpose**: Set up Alembic + create initial schema

**Files to Create/Modify**:
- `backend/alembic.ini` (Alembic config)
- `backend/alembic/env.py` (migration environment)
- `backend/alembic/versions/001_initial_schema.py` (initial migration)

**Commands**:
```bash
cd backend
alembic init alembic
alembic revision --autogenerate -m "Initial schema"
```

**Acceptance Criteria**:
- [ ] `alembic init` succeeds
- [ ] `alembic current` shows current revision
- [ ] Migration file contains all 8 tables
- [ ] Migration includes all indexes + constraints
- [ ] `alembic upgrade head` runs without errors (in test DB)
- [ ] Schema matches data-model.md

**Dependencies**: T-010 (data models)

**Estimated Time**: 2-3 hours

---

#### T-012: Document Entity Relationships [P]

**Purpose**: Create ER diagram + relationship documentation

**Files to Create/Modify**:
- `specs/1-textbook-generation/ER-diagram.md` (ASCII diagram + SQL references)

**Acceptance Criteria**:
- [ ] ER diagram shows all 8 entities
- [ ] Relationships correctly labeled (1:1, 1:N, N:N)
- [ ] Foreign keys documented
- [ ] Cardinality shown
- [ ] Matches data-model.md exactly

**Dependencies**: T-010 (data models)

**Estimated Time**: 1-2 hours

---

### Phase 3: CORE COMPONENTS

#### T-020: Build Chatbot Widget (React Component) [P]

**Purpose**: Implement frontend chatbot UI component

**Files to Create/Modify**:
- `src/components/ChatbotWidget/ChatbotWidget.tsx` â€” Main widget component
- `src/components/ChatbotWidget/ChatbotWidget.module.css` â€” Styling
- `src/components/ChatbotWidget/ChatbotWidget.test.tsx` â€” Unit tests
- `src/services/chatbot-client.ts` â€” API client

**Component Features**:
- Toggle button (floating corner)
- Message history display
- Input field with send button
- Source attribution display
- Loading indicator
- Error handling

**Acceptance Criteria**:
- [ ] Component renders without errors
- [ ] Toggle button works (open/close)
- [ ] Message input + send works
- [ ] API calls use correct endpoint (`/api/v1/chat`)
- [ ] Sources displayed with chapter + section
- [ ] Loading state shows spinner
- [ ] Error state displays user-friendly message
- [ ] Responsive on mobile + desktop
- [ ] Accessibility: ARIA labels, keyboard navigation

**Estimated Time**: 6-8 hours

---

#### T-021: Implement Embedding Service (MiniLM) [P]

**Purpose**: Setup sentence-transformers + embedding generation

**Files to Create/Modify**:
- `backend/src/services/embedding.py` â€” Embedding service
- `backend/src/scripts/embed_chapters.py` â€” Batch embedding script

**Acceptance Criteria**:
- [ ] MiniLM model loads successfully (first time downloads ~50MB)
- [ ] `embed_text(text: str) -> ndarray` works
- [ ] Returns 1024-dim vector for any input
- [ ] Batch processing: `embed_chunks(chunks: List[str]) -> List[ndarray]`
- [ ] ~100ms per chunk on CPU
- [ ] Error handling for empty strings, very long text
- [ ] No GPU required (CPU-only)

**Estimated Time**: 2-3 hours

---

#### T-022: Implement Retrieval Service (Qdrant) [P]

**Purpose**: Setup Qdrant client + search logic

**Files to Create/Modify**:
- `backend/src/services/qdrant.py` â€” Qdrant client wrapper
- `backend/src/services/retrieval.py` â€” Retrieval logic

**Acceptance Criteria**:
- [ ] Qdrant client connects (local Docker or cloud)
- [ ] Collection `textbook_chunks` created with cosine similarity
- [ ] `search(vector: ndarray, top_k=3) -> List[ChunkResult]`
- [ ] Results include chunk_id, chapter, section, similarity_score
- [ ] Handles Qdrant unavailability gracefully (returns empty list + logs error)
- [ ] Circuit breaker implemented (5 failures â†’ wait 60s)

**Estimated Time**: 3-4 hours

---

#### T-023: Build FastAPI App Structure [P]

**Purpose**: Setup main FastAPI app + routers

**Files to Create/Modify**:
- `backend/src/main.py` â€” FastAPI app entry point
- `backend/src/config.py` â€” Configuration + environment variables
- `backend/src/api/v1/__init__.py`
- `backend/src/api/v1/chat.py` â€” Chat router (endpoint stubs)
- `backend/src/api/v1/health.py` â€” Health router (stubs)
- `backend/src/db/connection.py` â€” Database connection pool
- `backend/src/db/models.py` â€” SQLAlchemy declarative base

**Acceptance Criteria**:
- [ ] FastAPI app starts on `uvicorn src.main:app --reload`
- [ ] Swagger UI available at `/docs`
- [ ] ReDoc available at `/redoc`
- [ ] Environment variables loaded from .env
- [ ] Database connection pool initialized
- [ ] Routers registered (`/api/v1/chat`, `/api/v1/health`)
- [ ] CORS configured (allow localhost + GitHub Pages domain)

**Estimated Time**: 3-4 hours

---

### Phase 4: API & INTEGRATION

#### T-030: Implement /api/v1/chat Endpoint

**Purpose**: Connect all pieces: query â†’ embedding â†’ retrieval â†’ response

**Files to Create/Modify**:
- `backend/src/api/v1/chat.py` â€” POST /chat endpoint
- `backend/src/services/chatbot.py` â€” Chatbot orchestration logic

**Endpoint Behavior**:
```python
@router.post("/chat")
async def chat(request: ChatRequest) -> ChatResponse:
    # 1. Validate query (max 1000 chars)
    # 2. Generate embedding
    # 3. Search Qdrant
    # 4. Retrieve metadata from Neon
    # 5. Aggregate answer
    # 6. Log query + response
    # 7. Return ChatResponse
```

**Acceptance Criteria**:
- [ ] Endpoint accepts POST with ChatRequest schema
- [ ] Query truncation: > 1000 chars â†’ truncated + logged
- [ ] Embedding generation: < 1 second
- [ ] Retrieval: top-3 chunks, cosine similarity
- [ ] Answer aggregation: meaningful text from chunks
- [ ] Source attribution: chapter + section for each source
- [ ] In-scope detection: >= 1 chunk with similarity > threshold
- [ ] Out-of-scope response: explicit "not covered" message
- [ ] Latency logging: actual p95 measured
- [ ] Error handling: 400 (invalid), 503 (DB down), 500 (unexpected)

**Dependencies**: T-020, T-021, T-022, T-023 (must be parallel complete)

**Estimated Time**: 4-6 hours

---

#### T-031: Implement /api/v1/health Endpoint

**Purpose**: System health check

**Files to Create/Modify**:
- `backend/src/api/v1/health.py` â€” Health check endpoint

**Endpoint Behavior**:
```python
@router.get("/health")
async def health() -> HealthResponse:
    # Check Qdrant connectivity
    # Check Neon connectivity
    # Return status + component states
```

**Acceptance Criteria**:
- [ ] Returns 200 OK when all systems healthy
- [ ] Returns 503 when critical system down
- [ ] Components tested: qdrant, neon
- [ ] Includes timestamp (ISO 8601)
- [ ] Response time < 1 second
- [ ] No side effects (read-only)

**Estimated Time**: 1-2 hours

---

#### T-032: Connect Qdrant Client

**Purpose**: Initialize Qdrant, handle connection pooling

**Files to Create/Modify**:
- `backend/src/services/qdrant.py` â€” Connection + pooling
- `backend/src/config.py` â€” Qdrant config (URL, API key)

**Acceptance Criteria**:
- [ ] Qdrant client initialized on app startup
- [ ] Connection pooling configured
- [ ] `QDRANT_URL` + `QDRANT_API_KEY` read from .env
- [ ] Graceful error handling if Qdrant unavailable
- [ ] Circuit breaker in place (5 failures â†’ wait)
- [ ] Health check endpoint verifies connectivity

**Estimated Time**: 2-3 hours

---

#### T-033: Connect Neon PostgreSQL

**Purpose**: Database connection, connection pooling, migrations

**Files to Create/Modify**:
- `backend/src/db/connection.py` â€” Connection pool + lifecycle
- `backend/src/config.py` â€” Neon config (DATABASE_URL)

**Acceptance Criteria**:
- [ ] Connection pool created (asyncpg)
- [ ] `NEON_DATABASE_URL` read from .env
- [ ] Migrations run on startup (alembic upgrade head)
- [ ] Connection pooling: min 2, max 10
- [ ] Graceful error handling if DB unavailable
- [ ] Health check endpoint verifies connectivity
- [ ] All 8 tables created + accessible

**Estimated Time**: 2-3 hours

---

### Phase 5: TESTING

#### T-040: Unit Tests (Embedding & Retrieval) [P]

**Purpose**: Test embedding generation + Qdrant search

**Files to Create/Modify**:
- `backend/tests/unit/test_embedding.py`
- `backend/tests/unit/test_retrieval.py`

**Test Cases**:
```
test_embedding.py:
  âœ“ test_embed_single_text() â€” Verify output shape (1024)
  âœ“ test_embed_batch() â€” Batch processing efficiency
  âœ“ test_embed_empty_string() â€” Handle edge case
  âœ“ test_embed_very_long_text() â€” Truncation + latency

test_retrieval.py:
  âœ“ test_search_returns_top_k() â€” Top-3 results
  âœ“ test_search_similarity_scores() â€” Scores in [0, 1]
  âœ“ test_search_empty_vector() â€” Handle invalid input
  âœ“ test_search_qdrant_unavailable() â€” Graceful degradation
  âœ“ test_circuit_breaker_opens() â€” After 5 failures
```

**Acceptance Criteria**:
- [ ] All tests pass: `pytest tests/unit/`
- [ ] Coverage >= 85% for embedding + retrieval
- [ ] No flaky tests (deterministic)
- [ ] Latency assertions: embedding < 1s, retrieval < 500ms

**Estimated Time**: 4-5 hours

---

#### T-041: Unit Tests (Chatbot Orchestration) [P]

**Purpose**: Test chatbot logic (query validation, aggregation)

**Files to Create/Modify**:
- `backend/tests/unit/test_chatbot.py`

**Test Cases**:
```
âœ“ test_query_truncation() â€” Queries > 1000 chars truncated
âœ“ test_in_scope_detection() â€” Similarity threshold logic
âœ“ test_out_of_scope_response() â€” No chunks â†’ "not covered"
âœ“ test_answer_aggregation() â€” Multiple chunks â†’ coherent answer
âœ“ test_source_attribution() â€” Sources properly formatted
âœ“ test_language_support() â€” Handle 'en' + 'ur'
âœ“ test_latency_logging() â€” Recorded for all queries
```

**Acceptance Criteria**:
- [ ] All tests pass: `pytest tests/unit/test_chatbot.py`
- [ ] Coverage >= 90%
- [ ] No external dependencies (mocked)

**Estimated Time**: 3-4 hours

---

#### T-042: Integration Tests (RAG Pipeline) [P]

**Purpose**: End-to-end test: query â†’ embedding â†’ retrieval â†’ response

**Files to Create/Modify**:
- `backend/tests/integration/test_rag_pipeline.py`

**Test Scenarios**:
```
âœ“ test_full_query_flow() â€” Query exists in chunks â†’ answer returned
âœ“ test_50_representative_queries() â€” Coverage across 6 chapters
âœ“ test_out_of_scope_queries() â€” 100% rejection rate
âœ“ test_latency_targets() â€” p95 < 2s, p99 < 3s
âœ“ test_db_recovery() â€” Connection lost â†’ reconnect + answer
âœ“ test_concurrent_queries() â€” 10 parallel queries
```

**Acceptance Criteria**:
- [ ] All integration tests pass (requires real/test Qdrant + Neon)
- [ ] 95% of in-scope queries retrieve relevant chunks
- [ ] 100% of out-of-scope queries return "not covered"
- [ ] Latency targets met (p95 < 2s)
- [ ] No data corruption after failures

**Estimated Time**: 6-8 hours

---

#### T-043: Contract Tests (API Schemas) [P]

**Purpose**: Validate request/response schemas match OpenAPI

**Files to Create/Modify**:
- `backend/tests/contract/test_api_schemas.py`

**Test Cases**:
```
âœ“ test_chat_request_schema() â€” Valid + invalid payloads
âœ“ test_chat_response_schema() â€” Response conforms to OpenAPI
âœ“ test_health_response_schema() â€” Status + components fields
âœ“ test_error_response_schema() â€” Error codes as spec
âœ“ test_endpoints_exist() â€” All routes registered
âœ“ test_cors_headers() â€” Correct allow-origins
```

**Acceptance Criteria**:
- [ ] All tests pass: `pytest tests/contract/`
- [ ] Schemas match contracts/chatbot-api.openapi.yaml exactly
- [ ] Invalid payloads rejected with 400
- [ ] No schema drift from spec

**Estimated Time**: 2-3 hours

---

### Phase 6: OBSERVABILITY & DEPLOYMENT

#### T-050: Implement Structured Logging

**Purpose**: Setup structlog + log to Neon

**Files to Create/Modify**:
- `backend/src/services/logger.py` â€” Structured logging config
- `backend/src/db/error_logs.py` â€” Error log persistence

**Features**:
- Timestamp, level, service, message, context (JSON)
- Log to stdout (development) + error_logs table (production)
- Request ID tracking (correlation)
- Performance metrics (latency per query)

**Acceptance Criteria**:
- [ ] All errors logged with full context
- [ ] Query latencies recorded in responses table
- [ ] Error_logs table queryable for debugging
- [ ] No sensitive data in logs (query text ok, no API keys)
- [ ] Latency: logging adds < 50ms overhead

**Estimated Time**: 3-4 hours

---

#### T-051: Setup CI/CD Pipeline (GitHub Actions)

**Purpose**: Automated tests, linting, type checking on PR

**Files to Create/Modify**:
- `.github/workflows/backend-tests.yml` â€” Run pytest on PR
- `.github/workflows/frontend-build.yml` â€” Build Docusaurus
- `.github/workflows/lint-and-format.yml` â€” ESLint, Black, Pylint

**Workflow Rules**:
- Run on: push to `1-textbook-generation`, PR to main
- Tests must pass: `pytest tests/ --cov`
- Linting must pass: `black`, `pylint`, `eslint`
- Type checking: `mypy backend/src`
- Coverage: >= 80%

**Acceptance Criteria**:
- [ ] Workflows defined in `.github/workflows/`
- [ ] Passing PR shows green checkmarks
- [ ] Failing tests block merge
- [ ] Coverage report available

**Estimated Time**: 3-4 hours

---

#### T-052: Configure Deployment (GitHub Pages + Vercel)

**Purpose**: Setup CD for frontend + backend

**Files to Create/Modify**:
- `.github/workflows/deploy.yml` â€” Deploy on main merge
- `.github/workflows/deploy-backend.yml` â€” Deploy to Vercel
- `vercel.json` â€” Vercel config (Python runtime)
- `book-website/docusaurus.config.ts` â€” GitHub Pages config

**Acceptance Criteria**:
- [ ] `yarn deploy` pushes to gh-pages branch
- [ ] GitHub Pages site live at `https://user.github.io/ai-textbook`
- [ ] Vercel deployment on main merge
- [ ] Backend API live at `https://ai-textbook-api.vercel.app`
- [ ] Environment variables configured in Vercel
- [ ] Rollback procedure documented

**Estimated Time**: 4-5 hours

---

#### T-053: Performance & Load Testing

**Purpose**: Verify latency targets under load

**Files to Create/Modify**:
- `backend/tests/performance/test_load.py` â€” Load test script

**Test Scenarios**:
```
âœ“ test_single_query_latency() â€” Single query < 2s
âœ“ test_10_concurrent_queries() â€” All < 3s
âœ“ test_100_queries_per_minute() â€” Throughput
âœ“ test_embedding_generation_time() â€” < 500ms per chunk
âœ“ test_cold_start() â€” Vercel cold start acceptable
```

**Acceptance Criteria**:
- [ ] Single query: p95 < 2s, p99 < 3s
- [ ] 10 concurrent queries: all complete < 3s
- [ ] 100 queries/min: no errors
- [ ] Embedding: < 500ms per chunk
- [ ] Cold start: < 5s acceptable (logged)

**Estimated Time**: 3-4 hours

---

### Phase 7: POLISH

#### T-060: Documentation & API Docs [P]

**Purpose**: README, Swagger, deployment guides

**Files to Create/Modify**:
- `backend/README.md` â€” Backend overview + setup
- `frontend/README.md` â€” Frontend overview + setup
- `.github/README.md` â€” Project overview
- Swagger docs auto-generated via FastAPI

**Acceptance Criteria**:
- [ ] README covers setup, testing, deployment
- [ ] Swagger docs accessible at `/docs`
- [ ] All endpoints documented with examples
- [ ] API contracts match OpenAPI spec

**Estimated Time**: 2-3 hours

---

#### T-061: Error Handling & Edge Cases [P]

**Purpose**: Comprehensive error handling

**Files to Create/Modify**:
- `backend/src/api/v1/exceptions.py` â€” Custom exceptions
- Error handling in endpoints + services

**Edge Cases**:
- Empty query
- Very long query (> 1000 chars)
- Non-Latin characters (Urdu)
- Concurrent requests
- DB connection lost
- Qdrant unavailable
- Invalid JSON payload
- Rate limiting (future)

**Acceptance Criteria**:
- [ ] All edge cases handled gracefully
- [ ] No unhandled exceptions reaching client
- [ ] Error messages user-friendly
- [ ] 5xx errors logged with context
- [ ] Graceful degradation (site readable even if chatbot down)

**Estimated Time**: 3-4 hours

---

#### T-062: Code Quality (Linting, Type Checking) [P]

**Purpose**: Enforce code standards

**Files to Modify**: All source files

**Tools**:
- Python: `black` (formatting), `pylint` (linting), `mypy` (type checking)
- TypeScript: `eslint`, `prettier`

**Acceptance Criteria**:
- [ ] `black --check backend/src` passes
- [ ] `pylint backend/src` score >= 8.0
- [ ] `mypy backend/src` no errors
- [ ] `eslint src/` passes
- [ ] No console.log or print statements left
- [ ] No TODO comments without context

**Estimated Time**: 2-3 hours

---

### Phase 8: VALIDATION & LAUNCH

#### T-070: Full End-to-End Testing

**Purpose**: Test entire system as user would

**Test Scenarios**:
```
âœ“ User visits textbook site (loads in < 2s)
âœ“ User reads chapter 1 (navigation works)
âœ“ User selects text â†’ chatbot appears
âœ“ User types question â†’ response in < 2s
âœ“ Response includes source attribution
âœ“ User navigates to chapter 2 (sidebar works)
âœ“ Repeat for all 6 chapters
```

**Acceptance Criteria**:
- [ ] Frontend loads successfully
- [ ] Chatbot widget functional
- [ ] All 6 chapters readable
- [ ] Chat responses accurate + timely
- [ ] No console errors
- [ ] Mobile view responsive

**Estimated Time**: 2-3 hours

---

#### T-071: Production Deployment

**Purpose**: Deploy to GitHub Pages + Vercel

**Steps**:
1. Tag release: `git tag v1.0.0`
2. Deploy frontend: `yarn deploy`
3. Deploy backend: `vercel --prod`
4. Verify: Test endpoints from production URLs
5. Monitor: Check logs for errors

**Acceptance Criteria**:
- [ ] Frontend live at GitHub Pages URL
- [ ] Backend live at Vercel URL
- [ ] Health check passes
- [ ] Sample queries return correct answers
- [ ] No 500 errors in production logs

**Estimated Time**: 1-2 hours

---

#### T-072: Monitor & Collect Feedback

**Purpose**: Post-launch monitoring + iteration

**Actions**:
- Monitor error logs daily (first week)
- Track query latencies + accuracy
- Collect user feedback (optional: form)
- Document learnings for Phase 2

**Acceptance Criteria**:
- [ ] Error rate < 1% (99.0% uptime)
- [ ] Latency p95 < 2s sustained
- [ ] Accuracy >= 95% on sample queries
- [ ] Zero critical issues in first week

**Estimated Time**: Ongoing (1 hour per day first week)

---

## Task Execution Summary

**Total Tasks**: 22 working tasks across 8 phases

**Phase Breakdown**:
- Phase 1 (SETUP): 3 sequential tasks
- Phase 2 (DATA): 3 parallel tasks
- Phase 3 (CORE): 4 parallel tasks
- Phase 4 (API): 4 sequential tasks
- Phase 5 (TESTS): 4 parallel tasks
- Phase 6 (OPS): 4 sequential tasks
- Phase 7 (POLISH): 3 parallel tasks
- Phase 8 (LAUNCH): 3 sequential tasks

**Estimated Total Time**: 70-90 hours (2-3 person-weeks)

**Parallel Opportunities**: 
- Phase 2 tasks can run in parallel (T-010, T-011, T-012)
- Phase 3 tasks can run in parallel (T-020, T-021, T-022, T-023)
- Phase 5 tasks can run in parallel (T-040, T-041, T-042, T-043)
- Phase 7 tasks can run in parallel (T-060, T-061, T-062)

**Quality Gates**:
- [ ] All tests pass before Phase 4
- [ ] All linting passes before Phase 6
- [ ] Coverage >= 80% before production

---

## Completion Tracking

**Status Legend**:
- âœ… COMPLETED
- ğŸ”„ IN PROGRESS
- â³ NOT STARTED
- âš ï¸ BLOCKED

**Phase 1**: â³ (ready to start)  
**Phase 2**: â³ (ready after Phase 1)  
**Phase 3**: â³ (ready after Phase 1)  
**Phase 4**: â³ (ready after Phase 3 completes)  
**Phase 5**: â³ (ready after Phase 4)  
**Phase 6**: â³ (ready after Phase 5)  
**Phase 7**: â³ (ready after Phase 6)  
**Phase 8**: â³ (ready after Phase 7)  

---

## Rollback Plan

If any phase fails:

1. **Phase 1 Failure**: Start over (no data loss)
2. **Phase 2-3 Failure**: Delete test data, re-run migrations
3. **Phase 4 Failure**: Revert endpoint code, keep migrations
4. **Phase 5 Failure**: Fix test issues, re-run tests
5. **Phase 6+ Failure**: Revert production deployment, use previous git tag

All data is version-controlled in git; easy recovery to any previous state.

---

**Next Action**: Execute Phase 1 tasks (T-001, T-002, T-003)

Ready for implementation! ğŸš€
